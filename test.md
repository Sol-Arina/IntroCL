### Задание 1 (5 баллов).

Ответьте на следующие вопросы (по возможности своими словами, а не копипастой):

1. Приведите классификацию формальных грамматик Хомского с примерами для категорий 2 и 3.
2. Что такое бейзлайн, пайплайн, SOTA? Приведите примеры. 
3. Какие элементы имплементации регулярного языка PCRE не являются собственно элементами грамматики регулярного языка по классификации Хомского?
4. Что такое языковая модель? Какие типы языковых моделей вы знаете?
5. Чем задача классификации отличается от задачи кластеризации?

Ответы:
1. Формальные грамматики Хомского делятся на 4 категории, на схеме можно представить как (0 (1 (2 (3)))). 
   0 - неограниченные, все формальные грамматики.
   1 - контекстно-зависимые, в обеих частях выражения могут быть терминальные и нетерминальные символы.
   2 - контекстно-свободные, например, языки программирования - Python, C#.
   3 - регулярные, например, регулярные выражения, язык ассемблера.

2. Бейзлайн - самое простое решение задачи, например, для детоксификации текста это будет замена мата звёздочками, либо удаление, если лемма слова совпала со словом в cловаре часто встречающейся нецензурной лексики. 
   Пайплайн - последовательность действий для выполнения задачи. В обработке текста пайплайн - этапы обработки, т.е токенизация, деление на предложения, нормализация, морфологическая разметка и т.д. 
   SOTA - лучшее решение задачи на данный момент, имеющее самую высокую оценку по принятым в этой задаче метрикам (языковая модель BERT, морфопарсер - RNNMorph).

3. Обратные ссылки, lookahead и lookbehind.

4. Языковая модель - это распределение вероятностей по последовательностям слов. Языковые модели можно разделить на статистические (n-грамные), нейронные (word2wec), предобученные (BERT), большие (GPT4).

5. Для классификации используется обучение с учителем, объекты распределяются по заранее определённым категориям по некоторым характеристикам (например, является ли письмо спамом).
Для кластеризации используется обучение без учителя, похожие вещи объединяются в группы на основе того, насколько они похожи (например, сегментация разных типов покупателей).


### Задание 2 (10 баллов). 

Попробуйте самостоятельно разработать метрики для оценки качества автоматического морфологического анализа: как бы вы оценивали качество лемматизации, приписывания частей речи и морфологических характеристик? Подумайте, какие вещи необходимо учесть. В результате у вас должны получиться три формулы, в которых будут фигурировать y_true (правильные ответы) и y_pred (предсказанные парсером ответы). Для морфологических признаков ответ явно будет складываться из нескольких категорий, например, род, число и падеж, нужно это учесть. Опишите словами ход своих рассуждений, приведите аргументы. Можно отталкиваться от уже существующих метрик, но если берете готовые, нужно их проанализировать.

1. Допустим, что для частей речи есть два значения 100 %, если предсказание правильное, или 0 %, если предсказание неправильное (y_true = y_prod -> True/False), так как часть речи может быть только одна, если есть контекст.
2. Для лемматизации можно сначала сравнить по буквам y_true и y_pred, если n-ая буква y_pred совпадает с n-ой буквой y_true, y_predletters += 1, если нет, y_predletters += 0. Если в y_pred больше букв, чем в y_true, прибавляем -1 столько раз, сколько лишних букв на конце (len(y_pred) - len(y_true)).
Для всех случаев - y_predletters/len(y_true), если len(y_pred) > len(y_true), то y_predletters - (len(y_pred) - len(y_true))/len(y_true). 
Например, y-true = кошка, y_pred = кошк. 4/5 = 0.8, y-true = представить, y_pred = представиться (11 - 2)/11 = 0.81

3. Для морфологических характеристик, возможно, сначала нужно как-то закодировать категории. Например, для существительных

Одушевлённость:
одуш. - 0
неодуш. - 1

Род:
м.р. - 10
ж.р. - 11
ср. р. - 100

Число:
ед. ч. - 101
мн. ч. - 110

Падеж:
Nom. - 111
Gen. - 1000
Dat. - 1001
...
Далее, если категория предсказана верно (здесь тоже думаю, можно верно-неверно считать как 100% или 0%), прибавляем 1 к сумме грамматических категорий, если нет, прибавляем 0. Чтобы получить результат, можно поделить кол-во правильных категорий, на общее кол-во категорий слова.

sum(y_pred)/len(y_true)

Например, у_true = [одуш., ж.р., ед. ч., Acc], y_pred = [одуш., ж.р., ед. ч., Nom]
3/4 = 0.75 

4. Общую точность можно рассчитать сложив результаты и разделив на кол-во параметров:

(100 if y_true == y_prod == True or 0 if y_true == y_prod == False) + (y_predletters/len(y_true)) + (sum(y_pred)/len(y_true))
--------------------------------------------------------------------------------------------------------------------------
                                                len [lemma, POS, Features]

в данном случае (100 + 80 + 75)/3 = 85% 



### Задание 3 (10 баллов). 

Выберите любую понравившуюся вам задачу NLP и исследуйте литературу по этой задаче. Какой у нее бейзлайн? Какая SOTA? В каком направлении ведутся современные исследования, связанные с этой задачей? Какие практические применения? Напишите коротенький конспект. 

Рекомендация: попробуйте искать survey - статьи на scholar.google.com.


Я решила выбрать задачу распознавания речи (Automatic Speech Recognition).

Бейзлайн для этой задачи чаще всего включает в себя использование:
1) cкрытых марковских моделей + смесей гауссовых распределений для акустического моделирования и n-граммных языковых моделей для языкового моделирования;
2) сверточных нейронных сетей с рекуррентными нейронными сетями для акустического моделирования и attention-based языковых моделей для языкового моделирования;
3) глубоких нейронных сетей со скрытыми марковскими моделями для акустического моделирования и n-граммных языковых моделей для языкового моделирования;
4) End-to-end моделей, таких как Connectionist Temporal Classification (CTC) или Sequence-to-Sequence моделей с механизмом внимания для акустического и языкового моделирования.

Примеры SOTA для этой задачи:
1) wav2vec 2.0 от Facebook - структура для самостоятельного изучения из необработанных аудиоданных; 
2) CLDNN-HMM модель - гибрид сверточной нейросети (CNN), Long Short-Term Memory (LSTM) network, глубокой нейросети (DNN) и скрытой марковской модели (HMM); 
3) SpecAugment с Noisy Student Training от Google;
4) CTC-based system от Microsoft; 
5) Listen Attend and Spell (LAS) от Google; 
6) Baidu's Deep Speech. 

Для достижения SOTA результатов обычно используются глубокие нейросети (DNN) и сверточные нейросети (CNN) для извлечения признаков из аудио-сигнала, гибридные модели, такие как CLDNN-HMM, объединяющая в себе свойства CNN, LSTM, DNN и HMM для достижения лучших результатов, и DNN-HMM + attention based end-to-end (E2E) модель, аугментация аудиоданных (добавление шума, изменение характеристик звука) для улучшения обучения на разных условиях записи, трансформер-архитектуры.

Современные исследования в области автоматического распознавания речи связаны с обработкой многоязычной речи, переключения кодов, улучшением точности распознавания при шумах и помехах, различных акцентах говорящих. Кроме того, ведутся исследования в области распознавания речи для малоресурсных языков (решения типа wav2vec 2.0 разрабатывают как раз в основном для распознавания речи на таких языках). 

Практические применения ASR:
1) системы голосового управления устройствами;
2) транскрибирование аудиозаписей, автоматические субтитры;
3) автоматический перевод речи;
4) системы распознавания команд в умных домах;
5) системы преобразования речи в текст для людей с ограниченными возможностями;
6) анализ звонков клиентов;
7) голосовые помощники.



### Задание 4 (15 баллов). 

Возьмите любой достаточно большой conll-файл и проведите мини-исследование, связанное с дативно-предикативными конструкциями (такими, как "мне холодно" и "сегодня холодно": предикативы такого рода могут присоединять дополнение в дат.п., а могут не присоединять), по [статье](https://www.dialog-21.ru/media/5937/zimmerlingav120.pdf) А.В. Циммерлинга. Вам понадобится написать скрипт, в котором будут автоматически рассчитываться метрики, приведенные Циммерлингом в своей статье. Придется учесть, что в формате UD нет части речи "предикатив" (можно посчитать метрики только для n верхних предикативов в его таблице - это будут конкретные слова), и подумать о том, как собирать все зависимые для текущего проверяемого токена. Советую взять Синтагрус (либо можно разобрать свои собственные тексты, но если будет их слишком мало, у вас метрики будут близки к нулю или просто нули). Для части группы, которая умеет писать код в классах, настойчиво советую оформить это в класс. 
